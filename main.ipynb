{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy, transformers, torch, numpy, huggingface_hub, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from transformers import pipeline, AutoModelForTokenClassification, AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "data = load_dataset(\"zhengyun21/PMC-Patients\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generateSentiment import generateSentiment\n",
    "\n",
    "# Add a preliminary sentiment label to the dataset\n",
    "sentiments = generateSentiment(data[\"train\"])\n",
    "data[\"train\"] = data[\"train\"].add_column(\"sentiment_label\", sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from findEntities import findEntities\n",
    "\n",
    "entities = findEntities(data[\"train\"])\n",
    "data[\"train\"] = data[\"train\"].add_column(\"entities\", entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = 0.8\n",
    "val_split = 0.1\n",
    "test_split = 1 - train_split - val_split\n",
    "assert train_split + val_split + test_split == 1\n",
    "\n",
    "data = data[\"train\"].train_test_split(\n",
    "    test_size=0.2, seed=0\n",
    ")\n",
    "test_val_split = data[\"test\"].train_test_split(\n",
    "    test_size=0.5, seed=0\n",
    ")\n",
    "# Combine splits into a single dataset\n",
    "split_dataset = {\n",
    "    \"train\": data[\"train\"],\n",
    "    \"validation\": test_val_split[\"train\"],\n",
    "    \"test\": test_val_split[\"test\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfFolder\n",
    "token = HfFolder.get_token()\n",
    "\n",
    "pretrained_model_name = \"chaoyi-wu/PMC_LLAMA_7B\"\n",
    "llama_model_name = \"meta-llama/Llama-3.2-1B\"\n",
    "model_name = llama_model_name if token else pretrained_model_name\n",
    "# model_name = pretrained_model_name\n",
    "pipe = pipeline(\"text-generation\", model=model_name, device=0 if torch.cuda.is_available() else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Do the actual finetuning\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "ner_training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=1e-4,\n",
    "    per_device_train_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    ")\n",
    "\n",
    "sentiment_training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=1e-4,\n",
    "    per_device_train_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    ")\n",
    "\n",
    "ner_trainer = Trainer(\n",
    "    model=ner_model,\n",
    "    args=ner_training_args,\n",
    "    train_dataset=split_dataset[\"train\"],\n",
    "    eval_dataset=split_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "sentiment_trainer = Trainer(\n",
    "    model=sentiment_model,\n",
    "    args=sentiment_training_args,\n",
    "    train_dataset=split_dataset[\"train\"],\n",
    "    eval_dataset=split_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract medical entities from the clinical note\n",
    "# Classify them into conditions, treatments, and outcomes\n",
    "def named_entity_recognition(note):\n",
    "    prompt = f\"\"\"\n",
    "Clinical Note: {note}\n",
    "You are a specialized medical language model designed to extract critical information from clinical notes. Given the clinical note, identify and extract the following entities:\n",
    "\n",
    "Symptoms: Physical or psychological conditions reported by the patient.\n",
    "Diagnoses: Medical conditions or diseases identified by the clinician.\n",
    "Treatments/Medications: Procedures, therapies, or drugs mentioned.\n",
    "Outcomes: Observations or indications of the patient's response to treatment or prognosis\n",
    "Return the extracted entities categorized into the corresponding groups. Use accurate medical terminology, and only include entities explicitly or implicitly mentioned in the text.\n",
    "Example Input:\n",
    "\"Patient reports severe fatigue and joint pain. Diagnosed with rheumatoid arthritis. Prescribed methotrexate. Follow-up shows improved joint mobility but persistent mild fatigue. Recent ESR levels have decreased but are still elevated.\"\n",
    "Expected Output:\n",
    "Entities:\n",
    "Symptoms: severe fatigue, joint pain\n",
    "Diagnoses: rheumatoid arthritis\n",
    "Treatments/Medications: methotrexate\n",
    "Outcomes: improved joint mobility, persistent mild fatigue\n",
    "    \"\"\"\n",
    "    result = pipe(note)\n",
    "    print(result)\n",
    "    for entity in result:\n",
    "        print(f\"Entity: {entity['word']} | Label: {entity['entity']} | Score: {entity['score']}\")\n",
    "    return result[0][\"generated_text\"].split(\"Entities:\")[-1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the patient's recovery risk sentiment\n",
    "# Positive (low risk), neutral (medium risk), or negative (high risk)\n",
    "def sentiment_analysis(note, entities):\n",
    "    prompt = f\"\"\"\n",
    "You are an expert medical language model tasked with analyzing clinical notes to determine patient recovery outcomes. Given a clinical note and extracted entities, assess the sentiment of the note with respect to the patient's recovery risk.\n",
    "Clinical Note: {note}\n",
    "Entities: {entities}\n",
    "Assess the sentiment of the clinical note with respect to the patient's recovery risk.\n",
    "Positive: Indicators of improvement or a high likelihood of recovery.\n",
    "Neutral: Indicators of stability or uncertain outcomes.\n",
    "Negative: Indicators of deterioration or a low likelihood of recovery.\n",
    "Example Input:\n",
    "\"Patient presents with severe dyspnea and elevated BNP levels. Treatment initiated with diuretics shows mild improvement. However, recurring chest pain persists, and cardiac markers remain elevated.\"\n",
    "Expected Output:\n",
    "Sentiment: Neutral\n",
    "    \"\"\"\n",
    "    result = pipe(note)\n",
    "    print(result)\n",
    "    return result[0][\"generated_text\"].split(\"Sentiment:\")[-1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_notes = []\n",
    "for i, entry in enumerate(data[\"train\"]):\n",
    "    title = entry[\"title\"]\n",
    "    note = entry[\"patient\"]\n",
    "    entities = named_entity_recognition(note)\n",
    "    sentiment = sentiment_analysis(note, entities)\n",
    "    labeled_notes.append({\"title\": title, \"note\": note, \"entities\": entities, \"sentiment\": sentiment})\n",
    "    break\n",
    "print(labeled_notes[0][\"entities\"])\n",
    "print(labeled_notes[0][\"sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_sentiment_map = defaultdict(lambda: {\"positive\": 0, \"neutral\": 0, \"negative\": 0})\n",
    "\n",
    "for entry in labeled_notes:\n",
    "    sentiment = entry[\"sentiment\"]\n",
    "    entities = entry[\"entities\"]\n",
    "    for entity in entities:\n",
    "        entity_sentiment_map[entity][sentiment] += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
